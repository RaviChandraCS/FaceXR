{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FaceXR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZVm3rCReVzv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRR135tV_GNj"
      },
      "source": [
        "import torch\n",
        "from torch import cuda\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn import Conv2d, ReLU, Flatten, MaxPool2d, BatchNorm2d, Dropout2d, Linear, Sequential, Module\n",
        "from torch.utils.data import random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import random\n",
        "import numpy\n",
        "from tabulate import tabulate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NnKwcfD_b5g"
      },
      "source": [
        "from network import *\n",
        "from metrics import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1c8iGJg-B9gs"
      },
      "source": [
        "root = '/content/drive/MyDrive/buffer64'\n",
        "batch = 64\n",
        "my_transforms = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])\n",
        "dataset = datasets.ImageFolder(root = root, transform = my_transforms)\n",
        "size = len(dataset)\n",
        "train_size = 80 * size // 100\n",
        "val_size = 10 * size // 100\n",
        "test_size = size - train_size - val_size\n",
        "split = [train_size, val_size, test_size]\n",
        "trainset, valset, testset = random_split(dataset, split)\n",
        "trainloader = DataLoader(trainset, batch, shuffle = True)\n",
        "valloader = DataLoader(valset, batch)\n",
        "testloader = DataLoader(testset, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0Yd8pWLC6tv",
        "outputId": "f6f080a9-ac69-453a-ba0d-86e215106ae3"
      },
      "source": [
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'using {device} device')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPtJzekHDa0m"
      },
      "source": [
        "net = Net().to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.001, momentum = 0.9, weight_decay = 0.001)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeIQVGgDDq-b"
      },
      "source": [
        "epochs = 60\n",
        "step = 10\n",
        "trainloss = []\n",
        "trainacc = []\n",
        "valloss = []\n",
        "valacc = []\n",
        "for epoch in range(1, epochs+1):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    run = 0\n",
        "    for data in trainloader:\n",
        "        images, labels = data\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images).to(device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        run += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    if epoch % step == 0:\n",
        "        net.eval()\n",
        "        valcorrect = 0\n",
        "        valtotal = 0\n",
        "        vrun = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                images = images.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = net(images).to(device)\n",
        "                loss = criterion(outputs, labels)\n",
        "                _, predictions = outputs.max(1)\n",
        "                valcorrect += (predictions == labels).sum()\n",
        "                valtotal += predictions.size(0)\n",
        "                vrun += loss.item()\n",
        "        valloss.append(vrun)\n",
        "        valacc.append(100 * valcorrect / valtotal)\n",
        "        print(f'Validation Loss {valloss[-1]}\\tAccuracy {valacc[-1]}')\n",
        "        net.train()\n",
        "                \n",
        "    trainloss.append(run)\n",
        "    trainacc.append(100 * correct / total)\n",
        "    print(f'Epoch {epoch}\\tLoss {trainloss[-1]}\\tAccuracy {trainacc[-1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKnx30jHFD7C"
      },
      "source": [
        "def accuracy_of_net(net, loader):\n",
        "    net.eval()\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(images).to(device)\n",
        "            _, predictions = outputs.max(1)\n",
        "            num_correct += (predictions == labels).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "        accuracy = 100 * num_correct / num_samples\n",
        "        net.train()\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu4bsk4abPWr"
      },
      "source": [
        "train_accuracy = accuracy_of_net(net, trainloader)\n",
        "validation_accuracy = accuracy_of_net(net, valloader)\n",
        "test_accuracy = accuracy_of_net(net, testloader)\n",
        "print(f'Accuracy on training set: {train_accuracy}%')\n",
        "print(f'Accuracy on validation set: {validation_accuracy}%')\n",
        "print(f'Accuracy on test set: {test_accuracy}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hADJnW68Hj2t"
      },
      "source": [
        "x = [i for i in range(epochs) if i % step == 0]\n",
        "tloss = [trainloss[i] for i in x]\n",
        "tacc = [trainacc[i] for i in x]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5gnZ4WqIUWQ"
      },
      "source": [
        "plt.plot(x, tloss)\n",
        "plt.legend(['training loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k3LQR_JIW-c"
      },
      "source": [
        "plt.plot(x, tacc)\n",
        "plt.legend(['training accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RVGi0GGIkwn"
      },
      "source": [
        "plt.plot(x, valloss)\n",
        "plt.legend(['validation loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImIY0klIOuSy"
      },
      "source": [
        "plt.plot(x, valacc)\n",
        "plt.legend(['validation accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-xzqujcOw0Q"
      },
      "source": [
        "plt.plot(x, tloss, label = 'training loss')\n",
        "plt.plot(x, valloss, label = 'val loss')\n",
        "plt.legend(['training loss', 'validation loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9BsIqpa7NPm"
      },
      "source": [
        "plt.plot(x, tacc, label = 'training accuracy')\n",
        "plt.plot(x, valacc, label = 'val accuracy')\n",
        "plt.legend(['training accuracy', 'validation accuracy'], loc = \"upper left\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRoZ6BENay9l"
      },
      "source": [
        "start = cuda.Event(enable_timing = True)\n",
        "end = cuda.Event(enable_timing = True)\n",
        "\n",
        "start.record()\n",
        "acc = accuracy_of_net(net, trainloader)\n",
        "acc = accuracy_of_net(net, valloader)\n",
        "acc = accuracy_of_net(net, testloader)\n",
        "end.record()\n",
        "\n",
        "cuda.synchronize()\n",
        "time = start.elapsed_time(end)\n",
        "print('Time taken to predict complete dataset = ', time)\n",
        "print(f'Average time taken per sample = {time / size}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LCyWz7LxXfi"
      },
      "source": [
        "def list_to_tensor(x, device):\n",
        "    if device == 'cuda':\n",
        "        return torch.cuda.FloatTensor(x)\n",
        "    return torch.FloatTensor(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHW0fj83g3bW"
      },
      "source": [
        "def get_metrics(net, loader):\n",
        "    net.eval()\n",
        "    pred = []\n",
        "    target = []\n",
        "    for images, labels in loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = net(images).to(device)\n",
        "        _, predictions = outputs.max(1)\n",
        "        for p in predictions:\n",
        "            pred.append(p.item())\n",
        "        for l in labels:\n",
        "            target.append(l.item())\n",
        "    \n",
        "    pred = list_to_tensor(pred, device)\n",
        "    target = list_to_tensor(target, device)\n",
        "\n",
        "    mape = MAPE(target, pred)\n",
        "    mae = mean_absolute_error(target, pred)\n",
        "    mse = mean_squared_error(target, pred)\n",
        "    rmse = root_mean_squared_error(target, pred)\n",
        "    net.train()\n",
        "    return {'mape' : mape, 'mae' : mae, 'mse' : mse, 'rmse' : rmse}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCuAMOp38yDz"
      },
      "source": [
        "def MAPE(target, prediction):\n",
        "    n = len(target)\n",
        "    target = [target[i] + 1 for i in range(n)]\n",
        "    prediction = [prediction[i] + 1 for i in range(n)]\n",
        "    s = 0\n",
        "    for i in range(n):\n",
        "        s += (abs((target[i] - prediction[i]) / target[i]))\n",
        "    s /= n\n",
        "    return s * 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hct9lWnqvzva"
      },
      "source": [
        "def print_metrics(metrics):\n",
        "    mape = metrics['mape']\n",
        "    mae = metrics['mae']\n",
        "    mse = metrics['mse']\n",
        "    rmse = metrics['rmse']\n",
        "    print(f'Mean Absolute Percentage Error:\\t{mape}')\n",
        "    print(f'Mean Absolute Error:\\t{mae}')\n",
        "    print(f'Mean Squared Error:\\t{mse}')\n",
        "    print(f'Root Mean Squared Error:\\t{rmse}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L1OMrpjvtdq"
      },
      "source": [
        "test_metrics = get_metrics(net, testloader)\n",
        "print_metrics(test_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1MEr-xmwhUD"
      },
      "source": [
        "train_metrics = get_metrics(net, trainloader)\n",
        "print_metrics(train_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-X-GtAL7omt"
      },
      "source": [
        "val_metrics = get_metrics(net, valloader)\n",
        "print_metrics(val_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BTkquco72hd"
      },
      "source": [
        "layers = 0\n",
        "conv_layers=[]\n",
        "children = list(net.children())\n",
        "\n",
        "for child in children:\n",
        "    if type(child) == Conv2d:\n",
        "        layers += 1\n",
        "        conv_layers.append(child)\n",
        "    elif type(child) == Sequential:\n",
        "        for layer in child.children():\n",
        "            if type(layer) == Conv2d:\n",
        "                layers += 1\n",
        "                conv_layers.append(layer)\n",
        "print('Number of convolutional layers = ', layers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF3OMiz_mhUG"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "img = cv.imread(\"/content/drive/MyDrive/buffer64/happy/image1128.png\")\n",
        "cv2_imshow(img)\n",
        "arr = np.array(img)\n",
        "img = Image.fromarray(arr)\n",
        "img = my_transforms(img)\n",
        "img = img.unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpfXRrpWmMZY"
      },
      "source": [
        "img = img.to(device)\n",
        "results = [conv_layers[0](img)]\n",
        "for i in range(1, len(conv_layers)):\n",
        "    results.append(conv_layers[i](results[-1]))\n",
        "outputs = results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap9EQ1-Lmfr9"
      },
      "source": [
        "# Feature maps\n",
        "for num_layer in range(len(outputs)):\n",
        "    plt.figure(figsize=(50, 10))\n",
        "    layer_viz = outputs[num_layer][0, :, :, :]\n",
        "    layer_viz = layer_viz.data\n",
        "    print(\"Layer \",num_layer+1)\n",
        "    for i, filter in enumerate(layer_viz):\n",
        "        if i == 16: \n",
        "            break\n",
        "        plt.subplot(2, 8, i + 1)\n",
        "        cpu_filter = filter.cpu()\n",
        "        plt.imshow(cpu_filter, cmap='gray')\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imJgHC8FqRhm"
      },
      "source": [
        "# Prediction\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image\n",
        "import cv2 as cv\n",
        "img = cv.imread(\"/content/image.png\")\n",
        "cv2_imshow(img)\n",
        "arr = np.array(img)\n",
        "img = Image.fromarray(arr)\n",
        "img = transform(img)\n",
        "img=img.unsqueeze(0)\n",
        "img = img.cuda()\n",
        "output = net(img).to(device)\n",
        "_, prediction = output.max(1)\n",
        "target_class = dataset.classes\n",
        "print(target_class[prediction])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
